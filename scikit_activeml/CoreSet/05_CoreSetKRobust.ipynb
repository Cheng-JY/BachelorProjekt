{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt, animation\n",
    "\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "from skactiveml.utils import MISSING_LABEL, labeled_indices, unlabeled_indices\n",
    "from skactiveml.visualization import plot_utilities, plot_decision_boundary\n",
    "from skactiveml.visualization._misc import mesh\n",
    "  \n",
    "from skactiveml.classifier import ParzenWindowClassifier\n",
    "\n",
    "from skactiveml.base import SingleAnnotatorPoolQueryStrategy\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "from scipy.optimize import milp, LinearConstraint, Bounds, minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoreSet(SingleAnnotatorPoolQueryStrategy):\n",
    "    \"\"\" Core Set Selection\n",
    "\n",
    "    This class implement various core-set based query strategies, i.e., the\n",
    "    standard greedy algorithm for k-center problem [1], the robust k-center\n",
    "    algorithm [1].\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    method: {'greedy', 'robust'}, default='greedy'\n",
    "        The method to solve the k-center problem, k-center-greedy and robust\n",
    "        k-center are possible\n",
    "    missing_label: scalar or string or np.nan or None, default=np.nan\n",
    "        Value to represent a missing label\n",
    "    random_state: int or np.random.RandomState\n",
    "        The random state to use\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    [1] O. Sener und S. Savarese, „ACTIVE LEARNING FOR CONVOLUTIONAL NEURAL \n",
    "    NETWORKS: A CORE-SET APPROACH“, 2018.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, method='greedy', missing_label=MISSING_LABEL, random_state=None\n",
    "    ):\n",
    "        super().__init__(\n",
    "            missing_label=missing_label, random_state=random_state\n",
    "        )\n",
    "\n",
    "        self.method = method\n",
    "    \n",
    "    def query(\n",
    "            self, \n",
    "            X, \n",
    "            y,\n",
    "            candidates=None,\n",
    "            batch_size=1,\n",
    "            return_utilities=False,\n",
    "        ):\n",
    "         \n",
    "         \"\"\" Query the next instances to be labeled\n",
    "\n",
    "         Parameters\n",
    "         ----------\n",
    "         X: array-like of shape (n_samples, n_features)\n",
    "            Training data set, usually complete, i.e. including the labeled and\n",
    "            unlabeled samples\n",
    "         y: array-like of shape (n_samples, )\n",
    "            Labels of the training data set (possibly including unlabeles ones\n",
    "            indicated by self.missing_label)\n",
    "         candidates: None or array-like of shape (n_candidates), dtype = int or\n",
    "            array-like of shape (n_candidates, n_features),\n",
    "            optional (default=None)\n",
    "            If candidates is None, the unlabeled samples from (X,y) are considered\n",
    "            as candidates\n",
    "         batch_size: int, optional(default=1)\n",
    "            The number of samples to be selectes in one AL cycle.\n",
    "         return_utilities: bool, optional(default=False)\n",
    "            If True, also return the utilites based on the query strategy\n",
    "\n",
    "         Returns\n",
    "         ----------\n",
    "         query_indices: numpy.ndarry of shape (batch_size, )\n",
    "            The query_indices indicate for which candidate sample a label is\n",
    "            to queried, e.g., `query_indices[0]` indicates the first selected\n",
    "            sample.\n",
    "         utilities: numpy.ndarray of shape (n_samples, )\n",
    "            The distance between each data point and its nearest center after\n",
    "            each selected sample of the batch\n",
    "         \"\"\"\n",
    "        \n",
    "         X, y, candidates, batch_size, return_utilities = self._validate_data(\n",
    "            X, y, candidates, batch_size, return_utilities, reset=True\n",
    "        )\n",
    "         \n",
    "         X_cand, mapping = self._transform_candidates(candidates, X, y)\n",
    "         selected_samples = labeled_indices(y, missing_label=self.missing_label)\n",
    "         \n",
    "         if self.method == 'greedy':\n",
    "             query_indices, utilities = self.k_greedy_center(X, selected_samples, batch_size)\n",
    "\n",
    "         if return_utilities:\n",
    "             return query_indices, utilities\n",
    "         else:\n",
    "             return query_indices\n",
    "    \n",
    "    def k_greedy_center(self, X, selected_samples, batch_size):\n",
    "        \"\"\"\n",
    "         An active learning method that greedily forms a batch to minimize \n",
    "         the maximum distance to a cluster center among all unlabeled\n",
    "         datapoints.\n",
    "\n",
    "         Parameters:\n",
    "         ----------\n",
    "         X: array-like of shape (n_samples, n_features)\n",
    "            Training data set, usually complete, i.e. including the labeled and\n",
    "            unlabeled samples\n",
    "         selected_samples: np.ndarray of shape (n_seleted_samples, )\n",
    "            index of datapoints already selectes\n",
    "         batch_size: int, optional(default=1)\n",
    "            The number of samples to be selectes in one AL cycle.\n",
    "        \n",
    "         Return:\n",
    "         ----------\n",
    "         new_samples: numpy.ndarry of shape (batch_size, )\n",
    "            The query_indices indicate for which candidate sample a label is\n",
    "            to queried from the candidates\n",
    "         utilities: numpy.ndarray of shape (n_samples, )\n",
    "            The distance between each data point and its nearest center after\n",
    "            each selected sample of the batch\n",
    "        \"\"\"\n",
    "\n",
    "        if len(selected_samples) > 0:\n",
    "            min_distances = self.update_distances(X, selected_samples)\n",
    "\n",
    "        query_indices = np.array([], dtype=int)\n",
    "\n",
    "        for _ in range(batch_size):\n",
    "            if len(selected_samples) == 0:\n",
    "                idx = self.random_state_.choice(np.arange(X.shape[0]))\n",
    "            else:\n",
    "                idx = np.argmax(min_distances)\n",
    "            assert idx not in selected_samples\n",
    "\n",
    "            query_indices = np.append(query_indices, [idx])\n",
    "            selected_samples = np.append(selected_samples, [idx])\n",
    "            min_distances = self.update_distances(X, selected_samples)\n",
    "        \n",
    "        min_distances = np.where(min_distances == 0, np.nan, min_distances)\n",
    "                \n",
    "        return query_indices, min_distances\n",
    "    \n",
    "    def update_distances(self, X, cluster_centers):\n",
    "        \"\"\" \n",
    "         Update min distances by given cluster centers.\n",
    "\n",
    "         Parameters:\n",
    "         ----------\n",
    "         X: array-like of shape (n_samples, n_features)\n",
    "            Training data set, usually complete, i.e. including the labeled and\n",
    "            unlabeled samples\n",
    "         cluster_centers: indices of cluster centers\n",
    "\n",
    "         Return:\n",
    "         ---------\n",
    "         dist: numpy.ndarray of shape (n_samples, )\n",
    "            The distance between each data point and its nearest center after\n",
    "            each selected sample of the batch\n",
    "        \"\"\"\n",
    "        if len(cluster_centers) == 0:\n",
    "            return np.full(shape=len(X), fill_value=np.nan)\n",
    "\n",
    "        cluster_center_feature = X[cluster_centers]\n",
    "        dist_matrix = pairwise_distances(X, cluster_center_feature)\n",
    "        dist = np.min(dist_matrix, axis=1).reshape(1,-1)\n",
    "\n",
    "        return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nearst_cluster_and_dist(X, u):\n",
    "    cluster_centers = np.where(u == 1)[0]\n",
    "    cluster_center_feature = X[cluster_centers]\n",
    "    dist_matrix = pairwise_distances(X, cluster_center_feature)\n",
    "    nearst_cluster_center = np.argmin(dist_matrix, axis=1)\n",
    "    dist = np.min(dist_matrix, axis=1)\n",
    "    return nearst_cluster_center, dist\n",
    "\n",
    "def get_u(X, cluster_centers):\n",
    "    u = np.zeros((X.shape[0]))\n",
    "    for ele in cluster_centers:\n",
    "        u[ele] = 1\n",
    "    return u\n",
    "\n",
    "def get_cluster_centers(u):\n",
    "    return np.where(u == 1)[0]\n",
    "\n",
    "def get_W(X, u):\n",
    "    nearst_cluster_center, _ = get_nearst_cluster_and_dist(X, u)\n",
    "    W = np.zeros((X.shape[0], len(np.where(u == 1)[0])))\n",
    "    for idx, element in enumerate(nearst_cluster_center):\n",
    "        W[idx][element] = 1\n",
    "    return W\n",
    "\n",
    "def get_outlier(X, u, upper_bound):\n",
    "    nearst_cluster_center, min_distance = get_nearst_cluster_and_dist(X, u)\n",
    "    outlier = np.zeros((X.shape[0], len(np.where(u == 1)[0])))\n",
    "    for idx, element in enumerate(nearst_cluster_center):\n",
    "        if(min_distance[idx]) > upper_bound:\n",
    "            outlier[idx][element] = 1\n",
    "    return outlier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [1. 0.]\n",
      " [0. 0.]\n",
      " [0. 1.]]\n",
      "5.0\n"
     ]
    }
   ],
   "source": [
    "# Begin of Test\n",
    "random_state = np.random.RandomState(0)\n",
    "# Build a dataset.\n",
    "X, y_true = make_blobs(n_samples=10, n_features=2,\n",
    "                       centers=[[0, 1], [-3, .5], [-1, -1], [2, 1], [1, -.5]],\n",
    "                       cluster_std=.7, random_state=random_state)\n",
    "y_true = y_true % 2\n",
    "y = np.full(shape=y_true.shape, fill_value=MISSING_LABEL)\n",
    "cluster_centers = [1,5]\n",
    "cluster_center_feature = X[cluster_centers]\n",
    "dist_matrix = pairwise_distances(X, cluster_center_feature)\n",
    "\n",
    "min_idx = np.argmin(dist_matrix, axis=1)\n",
    "\n",
    "W = np.zeros((X.shape[0], len(cluster_centers)))\n",
    "for idx, element in enumerate(min_idx):\n",
    "    W[idx][element] = 1\n",
    "\n",
    "u = get_u(X, cluster_centers)\n",
    "\n",
    "outlier = get_outlier(X, u, 1.5)\n",
    "print(outlier)\n",
    "\n",
    "sum = np.sum(outlier)\n",
    "print(sum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MIP():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def get_nearst_cluster_and_dist(self, X, u):\n",
    "        cluster_centers = np.where(u == 1)[0]\n",
    "        cluster_center_feature = X[cluster_centers]\n",
    "        dist_matrix = pairwise_distances(X, cluster_center_feature)\n",
    "        nearst_cluster_center = np.argmin(dist_matrix, axis=1)\n",
    "        dist = np.min(dist_matrix, axis=1)\n",
    "        return nearst_cluster_center, dist\n",
    "\n",
    "    def get_u(self, X, cluster_centers):\n",
    "        u = np.zeros((X.shape[0]))\n",
    "        for ele in cluster_centers:\n",
    "            u[ele] = 1\n",
    "        return u\n",
    "\n",
    "    def get_cluster_centers(self, u):\n",
    "        return np.where(u == 1)[0]\n",
    "\n",
    "    def get_W(self, X, u):\n",
    "        nearst_cluster_center, _ = get_nearst_cluster_and_dist(X, u)\n",
    "        W = np.zeros((X.shape[0], len(np.where(u == 1)[0])))\n",
    "        for idx, element in enumerate(nearst_cluster_center):\n",
    "            W[idx][element] = 1\n",
    "        return W\n",
    "\n",
    "    def get_outlier(self, X, u, upper_bound):\n",
    "        nearst_cluster_center, min_distance = get_nearst_cluster_and_dist(X, u)\n",
    "        outlier = np.zeros((X.shape[0], len(np.where(u == 1)[0])))\n",
    "        for idx, element in enumerate(nearst_cluster_center):\n",
    "            if(min_distance[idx]) > upper_bound:\n",
    "                outlier[idx][element] = 1\n",
    "        return outlier\n",
    "    \n",
    "    def con1(self, batch_size, selected_samples, u):\n",
    "        return np.sum(u) - batch_size - len(selected_samples)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying to implement MIP\n",
    "def objective(u):\n",
    "    outlier = get_outlier(X, u, 1.5)\n",
    "    sum = np.sum(outlier)\n",
    "    return sum\n",
    "\n",
    "def constaints1(u):\n",
    "    return np.sum(u)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn import clone\n",
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "\n",
    "from skactiveml.base import SingleAnnotatorPoolQueryStrategy, SkactivemlClassifier\n",
    "from skactiveml.utils import (\n",
    "    MISSING_LABEL,\n",
    "    check_type,\n",
    "    check_equal_missing_label,\n",
    "    unlabeled_indices\n",
    ")\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from skactiveml.classifier import SklearnClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Badge(SingleAnnotatorPoolQueryStrategy):\n",
    "    def __init__(\n",
    "            self,\n",
    "            missing_label=MISSING_LABEL,\n",
    "            random_state=None\n",
    "    ):\n",
    "        super().__init__(\n",
    "            missing_label=missing_label, random_state=random_state\n",
    "        )\n",
    "\n",
    "    def query(\n",
    "            self,\n",
    "            X,\n",
    "            y,\n",
    "            clf,\n",
    "            candidates=None,\n",
    "            batch_size=1,\n",
    "            return_utilities=False,\n",
    "            return_embeddings=False,\n",
    "    ):\n",
    "        # Validate input parameters\n",
    "        X, y, candidates, batch_size, return_utilities = self._validate_data(\n",
    "            X, y, candidates, batch_size, return_utilities, reset=True\n",
    "        )\n",
    "\n",
    "        X_cand, mapping = self._transform_candidates(candidates, X, y)\n",
    "\n",
    "        # Validate classifier type\n",
    "        check_type(clf, \"clf\", SkactivemlClassifier)\n",
    "        check_equal_missing_label(clf.missing_label, self.missing_label_)\n",
    "        if not isinstance(return_embeddings, bool):\n",
    "            raise TypeError(\"'return_embeddings' must be a boolean.\")\n",
    "\n",
    "        # Fit the classifier\n",
    "        clf = clone(clf).fit(X, y)\n",
    "\n",
    "        # find the unlabeled dataset\n",
    "        if candidates is None:\n",
    "            X_unlbld = X_cand\n",
    "            unlbld_mapping = mapping\n",
    "        elif mapping is not None:\n",
    "            unlbld_mapping = unlabeled_indices(y[mapping], missing_label=self.missing_label)\n",
    "            X_unlbld = X_cand[unlbld_mapping]\n",
    "            unlbld_mapping = mapping[unlbld_mapping]\n",
    "        else:\n",
    "            X_unlbld = X_cand\n",
    "            unlbld_mapping = np.arange(len(X_cand))\n",
    "\n",
    "        # Gradient embedding, aka predict class membership probabilities\n",
    "        \n",
    "        probas = clf.predict_proba(X_unlbld)\n",
    "        print(probas)\n",
    "        p_max = np.max(probas, axis=1).reshape(-1,1) #gaile\n",
    "        g_x = (p_max - 1) * X_unlbld\n",
    "\n",
    "        # init the utilities\n",
    "        if mapping is not None:\n",
    "            utilities = np.full(shape=(batch_size, X.shape[0]), fill_value=np.nan)\n",
    "        else:\n",
    "            utilities = np.full(shape=(batch_size, X_cand.shape[0]), fill_value=np.nan)\n",
    "\n",
    "        # 2. sampling with kmeans++\n",
    "        query_indicies = np.array([], dtype=int)\n",
    "        query_indicies_in_unlbld = np.array([], dtype=int)\n",
    "        d_2_s = []\n",
    "        for i in range(batch_size):\n",
    "            if i == 0:\n",
    "                d_2 = _d_2(g_x, [])\n",
    "            else:\n",
    "                d_2 = _d_2(g_x, [idx_in_unlbld], d_2_s[i-1])\n",
    "            d_2_s.append(d_2)\n",
    "\n",
    "            d_2_sum = np.sum(d_2)\n",
    "            if i == 0 or d_2_sum == 0:\n",
    "                d_2 = np.ones(shape=len(g_x))\n",
    "                d_2[query_indicies_in_unlbld] = 0\n",
    "                d_2_sum = np.sum(d_2)\n",
    "            \n",
    "            d_probas = d_2 / d_2_sum\n",
    "            \n",
    "            utilities[i, unlbld_mapping] = d_probas\n",
    "            utilities[i, query_indicies] = np.nan\n",
    "\n",
    "            idx_in_unlbld_array = self.random_state_.choice(len(d_probas), 1, replace=False, p=d_probas)\n",
    "            \n",
    "            idx_in_unlbld = idx_in_unlbld_array[0]\n",
    "            query_indicies_in_unlbld = np.append(query_indicies_in_unlbld, idx_in_unlbld_array)\n",
    "            \n",
    "            idx = unlbld_mapping[idx_in_unlbld]\n",
    "            query_indicies = np.append(query_indicies, [idx])\n",
    "        \n",
    "        if return_utilities:\n",
    "            return query_indicies, utilities\n",
    "        else:\n",
    "            return query_indicies\n",
    "\n",
    "\n",
    "def _d_2(g_x, query_indicies, d_latest=None):\n",
    "    if len(query_indicies) == 0:\n",
    "        return np.full(shape=len(g_x), fill_value=np.inf)\n",
    "    g_query_indicies = g_x[query_indicies]\n",
    "    _, D = pairwise_distances_argmin_min(X=g_x, Y=g_query_indicies)\n",
    "    if d_latest is not None:\n",
    "        D = np.minimum(d_latest, D)\n",
    "    D2 = np.square(D)\n",
    "    D2_sum = np.sum(D2)\n",
    "    if D2_sum == 0:\n",
    "        return np.full(shape=len(g_x), fill_value=np.inf)\n",
    "    return D2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y_true = make_classification(n_features=2, n_redundant=0, random_state=0)\n",
    "y = np.full(shape=y_true.shape, fill_value=MISSING_LABEL)\n",
    "clf = SklearnClassifier(LogisticRegression(), classes=np.unique(y_true))\n",
    "qs = Badge(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]]\n",
      "[4 2 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/skactiveml/classifier/_wrapper.py:320: UserWarning: The 'base_estimator' could not be fitted because of 'There is no labeled data.'. Therefore, the class labels of the samples are counted and will be used to make predictions. The class label distribution is `_label_counts=[0, 0]`.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/skactiveml/classifier/_wrapper.py:219: UserWarning: Since the 'base_estimator' could not be fitted when calling the `fit` method, the class label distribution`_label_counts=[0, 0]` is used to make the predictions.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "query = qs.query(X[:5], y[:5], clf, candidates=None, batch_size=3)\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]]\n",
      "[4 2 3]\n",
      "[[0.2        0.2        0.2        0.2        0.2       ]\n",
      " [0.23279271 0.27312903 0.30139662 0.19268163        nan]\n",
      " [0.03267711 0.00610958        nan 0.96121331        nan]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/skactiveml/classifier/_wrapper.py:320: UserWarning: The 'base_estimator' could not be fitted because of 'There is no labeled data.'. Therefore, the class labels of the samples are counted and will be used to make predictions. The class label distribution is `_label_counts=[0, 0]`.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/skactiveml/classifier/_wrapper.py:219: UserWarning: Since the 'base_estimator' could not be fitted when calling the `fit` method, the class label distribution`_label_counts=[0, 0]` is used to make the predictions.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "query, utilities = qs.query(X[:5], y[:5], clf, candidates=None, batch_size=3, return_utilities=True)\n",
    "print(query)\n",
    "print(utilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.62511502 0.37488498]\n",
      " [0.37775923 0.62224077]\n",
      " [0.0930193  0.9069807 ]\n",
      " [0.77232873 0.22767127]\n",
      " [0.62482864 0.37517136]\n",
      " [0.62863896 0.37136104]\n",
      " [0.79984337 0.20015663]\n",
      " [0.07336398 0.92663602]\n",
      " [0.48481203 0.51518797]\n",
      " [0.2684722  0.7315278 ]\n",
      " [0.25460785 0.74539215]\n",
      " [0.78241932 0.21758068]\n",
      " [0.79685072 0.20314928]\n",
      " [0.01462891 0.98537109]\n",
      " [0.17932071 0.82067929]\n",
      " [0.48403444 0.51596556]\n",
      " [0.87616605 0.12383395]\n",
      " [0.24597539 0.75402461]\n",
      " [0.71322158 0.28677842]\n",
      " [0.79553289 0.20446711]\n",
      " [0.87887735 0.12112265]\n",
      " [0.06857487 0.93142513]\n",
      " [0.00153022 0.99846978]\n",
      " [0.7635098  0.2364902 ]\n",
      " [0.0035249  0.9964751 ]\n",
      " [0.41262771 0.58737229]\n",
      " [0.28806432 0.71193568]\n",
      " [0.0257005  0.9742995 ]\n",
      " [0.42350324 0.57649676]\n",
      " [0.78020576 0.21979424]\n",
      " [0.01649936 0.98350064]\n",
      " [0.67626141 0.32373859]\n",
      " [0.0800561  0.9199439 ]\n",
      " [0.74563633 0.25436367]\n",
      " [0.94338196 0.05661804]\n",
      " [0.10634404 0.89365596]\n",
      " [0.04405831 0.95594169]\n",
      " [0.55234121 0.44765879]\n",
      " [0.43123367 0.56876633]\n",
      " [0.40180296 0.59819704]\n",
      " [0.94476096 0.05523904]\n",
      " [0.30984752 0.69015248]\n",
      " [0.03520848 0.96479152]\n",
      " [0.9212543  0.0787457 ]\n",
      " [0.01261339 0.98738661]\n",
      " [0.74800156 0.25199844]\n",
      " [0.84418092 0.15581908]\n",
      " [0.00219636 0.99780364]\n",
      " [0.94279476 0.05720524]\n",
      " [0.96198745 0.03801255]]\n",
      "[61 81 80]\n",
      "[[       nan        nan        nan        nan        nan        nan\n",
      "         nan        nan        nan        nan        nan        nan\n",
      "         nan        nan        nan        nan        nan        nan\n",
      "         nan        nan        nan        nan        nan        nan\n",
      "         nan        nan        nan        nan        nan        nan\n",
      "         nan        nan        nan        nan        nan        nan\n",
      "         nan        nan        nan        nan        nan        nan\n",
      "         nan        nan        nan        nan        nan        nan\n",
      "         nan        nan 0.02       0.02       0.02       0.02\n",
      "  0.02       0.02       0.02       0.02       0.02       0.02\n",
      "  0.02       0.02       0.02       0.02       0.02       0.02\n",
      "  0.02       0.02       0.02       0.02       0.02       0.02\n",
      "  0.02       0.02       0.02       0.02       0.02       0.02\n",
      "  0.02       0.02       0.02       0.02       0.02       0.02\n",
      "  0.02       0.02       0.02       0.02       0.02       0.02\n",
      "  0.02       0.02       0.02       0.02       0.02       0.02\n",
      "  0.02       0.02       0.02       0.02      ]\n",
      " [       nan        nan        nan        nan        nan        nan\n",
      "         nan        nan        nan        nan        nan        nan\n",
      "         nan        nan        nan        nan        nan        nan\n",
      "         nan        nan        nan        nan        nan        nan\n",
      "         nan        nan        nan        nan        nan        nan\n",
      "         nan        nan        nan        nan        nan        nan\n",
      "         nan        nan        nan        nan        nan        nan\n",
      "         nan        nan        nan        nan        nan        nan\n",
      "         nan        nan 0.0360431  0.02054517 0.01120372 0.01796366\n",
      "  0.0460693  0.02968627 0.0206378  0.00924372 0.08862467 0.00301156\n",
      "  0.01104432        nan 0.00353802 0.0129552  0.00402602 0.08929759\n",
      "  0.01190408 0.01077354 0.01851242 0.0187954  0.01051853 0.00971346\n",
      "  0.01165625 0.00474151 0.01186118 0.07391015 0.02279079 0.01079219\n",
      "  0.05335565 0.00558537 0.0134396  0.04147734 0.01390203 0.02618583\n",
      "  0.00975379 0.01017255 0.00819698 0.08483933 0.00571044 0.00580134\n",
      "  0.00912933 0.00636656 0.01148077 0.01052234 0.01152374 0.01802431\n",
      "  0.00674844 0.0115999  0.00402669 0.01229805]\n",
      " [       nan        nan        nan        nan        nan        nan\n",
      "         nan        nan        nan        nan        nan        nan\n",
      "         nan        nan        nan        nan        nan        nan\n",
      "         nan        nan        nan        nan        nan        nan\n",
      "         nan        nan        nan        nan        nan        nan\n",
      "         nan        nan        nan        nan        nan        nan\n",
      "         nan        nan        nan        nan        nan        nan\n",
      "         nan        nan        nan        nan        nan        nan\n",
      "         nan        nan 0.00136871 0.0396863  0.02092771 0.03464684\n",
      "  0.00087259 0.00702696 0.02582926 0.01424591 0.06450278 0.0015121\n",
      "  0.02033646        nan 0.00208698 0.02798243 0.0027024  0.06605575\n",
      "  0.0236259  0.01935148 0.03264094 0.031737   0.01844621 0.01573058\n",
      "  0.02265243 0.00374826 0.02345594 0.03873578 0.04387314 0.01941853\n",
      "  0.01075164 0.00520116 0.0301141         nan 0.03222205 0.01250385\n",
      "  0.01586148 0.01725267 0.01120223 0.05506791 0.00543671 0.00561117\n",
      "  0.01389553 0.00675782 0.02197551 0.01845958 0.02214031 0.03440126\n",
      "  0.00759283 0.02243392 0.00270329 0.02521562]]\n"
     ]
    }
   ],
   "source": [
    "y[:50] = y_true[:50]\n",
    "query, utilities = qs.query(X, y, clf, candidates=None, batch_size=3, return_utilities=True)\n",
    "print(query)\n",
    "print(utilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.62511502 0.37488498]\n",
      " [0.37775923 0.62224077]\n",
      " [0.0930193  0.9069807 ]\n",
      " [0.77232873 0.22767127]\n",
      " [0.62482864 0.37517136]\n",
      " [0.62863896 0.37136104]\n",
      " [0.79984337 0.20015663]\n",
      " [0.07336398 0.92663602]\n",
      " [0.48481203 0.51518797]\n",
      " [0.2684722  0.7315278 ]]\n",
      "[2 8 4]\n",
      "[[1.00000000e-01 1.00000000e-01 1.00000000e-01 1.00000000e-01\n",
      "  1.00000000e-01 1.00000000e-01 1.00000000e-01 1.00000000e-01\n",
      "  1.00000000e-01 1.00000000e-01]\n",
      " [1.25682550e-01 2.68979685e-02            nan 4.79296172e-02\n",
      "  1.78660497e-01 9.54018139e-02 5.48850504e-02 1.12172367e-03\n",
      "  4.27446035e-01 4.19747446e-02]\n",
      " [2.62050892e-01 1.20025807e-02            nan 3.81104076e-02\n",
      "  4.57622164e-01 1.50990262e-01 4.99739650e-02 2.08740846e-05\n",
      "             nan 2.92288546e-02]]\n"
     ]
    }
   ],
   "source": [
    "query, utilities = qs.query(X, y, clf, candidates=X[50:60], batch_size=3, return_utilities=True)\n",
    "print(query)\n",
    "print(utilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum([np.inf, np.inf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(5, 1, replace=False, p=[0.1, 0, 0.3, 0.6, 0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

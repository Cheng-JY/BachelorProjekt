{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt, animation\n",
    "\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "from skactiveml.utils import MISSING_LABEL, labeled_indices, unlabeled_indices\n",
    "from skactiveml.visualization import plot_utilities, plot_decision_boundary\n",
    "from skactiveml.visualization._misc import mesh\n",
    "  \n",
    "from skactiveml.classifier import ParzenWindowClassifier\n",
    "\n",
    "from skactiveml.base import SingleAnnotatorPoolQueryStrategy\n",
    "from sklearn.metrics import pairwise_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoreSet(SingleAnnotatorPoolQueryStrategy):\n",
    "    \"\"\" Core Set Selection\n",
    "\n",
    "    This class implement various core-set based query strategies, i.e., the\n",
    "    standard greedy algorithm for k-center problem [1], the robust k-center\n",
    "    algorithm [1].\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    method: {'greedy', 'robust'}, default='greedy'\n",
    "        The method to solve the k-center problem, k-center-greedy and robust\n",
    "        k-center are possible\n",
    "    missing_label: scalar or string or np.nan or None, default=np.nan\n",
    "        Value to represent a missing label\n",
    "    random_state: int or np.random.RandomState\n",
    "        The random state to use\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    [1] O. Sener und S. Savarese, „ACTIVE LEARNING FOR CONVOLUTIONAL NEURAL \n",
    "    NETWORKS: A CORE-SET APPROACH“, 2018.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, method='greedy', missing_label=MISSING_LABEL, random_state=None\n",
    "    ):\n",
    "        super().__init__(\n",
    "            missing_label=missing_label, random_state=random_state\n",
    "        )\n",
    "\n",
    "        self.method = method\n",
    "    \n",
    "    def query(\n",
    "            self, \n",
    "            X, \n",
    "            y,\n",
    "            candidates=None,\n",
    "            batch_size=1,\n",
    "            return_utilities=False,\n",
    "        ):\n",
    "         \n",
    "         \"\"\" Query the next instances to be labeled\n",
    "\n",
    "         Parameters\n",
    "         ----------\n",
    "         X: array-like of shape (n_samples, n_features)\n",
    "            Training data set, usually complete, i.e. including the labeled and\n",
    "            unlabeled samples\n",
    "         y: array-like of shape (n_samples, )\n",
    "            Labels of the training data set (possibly including unlabeles ones\n",
    "            indicated by self.missing_label)\n",
    "         candidates: None or array-like of shape (n_candidates), dtype = int or\n",
    "            array-like of shape (n_candidates, n_features),\n",
    "            optional (default=None)\n",
    "            If candidates is None, the unlabeled samples from (X,y) are considered\n",
    "            as candidates\n",
    "         batch_size: int, optional(default=1)\n",
    "            The number of samples to be selectes in one AL cycle.\n",
    "         return_utilities: bool, optional(default=False)\n",
    "            If True, also return the utilites based on the query strategy\n",
    "\n",
    "         Returns\n",
    "         ----------\n",
    "         query_indices: numpy.ndarry of shape (batch_size, )\n",
    "            The query_indices indicate for which candidate sample a label is\n",
    "            to queried, e.g., `query_indices[0]` indicates the first selected\n",
    "            sample.\n",
    "         utilities: numpy.ndarray of shape (n_samples, )\n",
    "            The distance between each data point and its nearest center after\n",
    "            each selected sample of the batch\n",
    "         \"\"\"\n",
    "        \n",
    "         X, y, candidates, batch_size, return_utilities = self._validate_data(\n",
    "            X, y, candidates, batch_size, return_utilities, reset=True\n",
    "        )\n",
    "         \n",
    "         X_cand, mapping = self._transform_candidates(candidates, X, y)\n",
    "         selected_samples = labeled_indices(y, missing_label=self.missing_label)\n",
    "         \n",
    "         if self.method == 'greedy':\n",
    "             query_indices, utilities = self.k_greedy_center(X, selected_samples, batch_size)\n",
    "\n",
    "         if return_utilities:\n",
    "             return query_indices, utilities\n",
    "         else:\n",
    "             return query_indices\n",
    "    \n",
    "    def k_greedy_center(self, X, selected_samples, batch_size):\n",
    "        \"\"\"\n",
    "         An active learning method that greedily forms a batch to minimize \n",
    "         the maximum distance to a cluster center among all unlabeled\n",
    "         datapoints.\n",
    "\n",
    "         Parameters:\n",
    "         ----------\n",
    "         X: array-like of shape (n_samples, n_features)\n",
    "            Training data set, usually complete, i.e. including the labeled and\n",
    "            unlabeled samples\n",
    "         selected_samples: np.ndarray of shape (n_seleted_samples, )\n",
    "            index of datapoints already selectes\n",
    "         batch_size: int, optional(default=1)\n",
    "            The number of samples to be selectes in one AL cycle.\n",
    "        \n",
    "         Return:\n",
    "         ----------\n",
    "         new_samples: numpy.ndarry of shape (batch_size, )\n",
    "            The query_indices indicate for which candidate sample a label is\n",
    "            to queried from the candidates\n",
    "         utilities: numpy.ndarray of shape (n_samples, )\n",
    "            The distance between each data point and its nearest center after\n",
    "            each selected sample of the batch\n",
    "        \"\"\"\n",
    "\n",
    "        if len(selected_samples) > 0:\n",
    "            min_distances = self.update_distances(X, selected_samples)\n",
    "\n",
    "        query_indices = np.array([], dtype=int)\n",
    "\n",
    "        for _ in range(batch_size):\n",
    "            if len(selected_samples) == 0:\n",
    "                idx = self.random_state_.choice(np.arange(X.shape[0]))\n",
    "            else:\n",
    "                idx = np.argmax(min_distances)\n",
    "            assert idx not in selected_samples\n",
    "\n",
    "            query_indices = np.append(query_indices, [idx])\n",
    "            selected_samples = np.append(selected_samples, [idx])\n",
    "            min_distances = self.update_distances(X, selected_samples)\n",
    "        \n",
    "        min_distances = np.where(min_distances == 0, np.nan, min_distances)\n",
    "                \n",
    "        return query_indices, min_distances\n",
    "    \n",
    "    def update_distances(self, X, cluster_centers):\n",
    "        \"\"\" \n",
    "         Update min distances by given cluster centers.\n",
    "\n",
    "         Parameters:\n",
    "         ----------\n",
    "         X: array-like of shape (n_samples, n_features)\n",
    "            Training data set, usually complete, i.e. including the labeled and\n",
    "            unlabeled samples\n",
    "         cluster_centers: indices of cluster centers\n",
    "\n",
    "         Return:\n",
    "         ---------\n",
    "         dist: numpy.ndarray of shape (n_samples, )\n",
    "            The distance between each data point and its nearest center after\n",
    "            each selected sample of the batch\n",
    "        \"\"\"\n",
    "        if len(cluster_centers) == 0:\n",
    "            return np.full(shape=len(X), fill_value=np.nan)\n",
    "\n",
    "        cluster_center_feature = X[cluster_centers]\n",
    "        dist_matrix = pairwise_distances(X, cluster_center_feature)\n",
    "        dist = np.min(dist_matrix, axis=1).reshape(1,-1)\n",
    "\n",
    "        return dist"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

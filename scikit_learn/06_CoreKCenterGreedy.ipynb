{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt, animation\n",
    "\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "from skactiveml.utils import MISSING_LABEL, labeled_indices, unlabeled_indices\n",
    "from skactiveml.visualization import plot_utilities, plot_decision_boundary\n",
    "from skactiveml.visualization._misc import mesh\n",
    "from skactiveml.base import *\n",
    "  \n",
    "from skactiveml.classifier import ParzenWindowClassifier\n",
    "\n",
    "from skactiveml.base import SingleAnnotatorPoolQueryStrategy\n",
    "from sklearn.metrics import pairwise_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoreSet(SingleAnnotatorPoolQueryStrategy):\n",
    "    \"\"\" Core Set Selection\n",
    "\n",
    "    This class implement various core-set based query strategies, i.e., the\n",
    "    standard greedy algorithm for k-center problem [1], the robust k-center\n",
    "    algorithm [1].\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    method: {'greedy', 'robust'}, default='greedy'\n",
    "        The method to solve the k-center problem, k-center-greedy and robust\n",
    "        k-center are possible\n",
    "    missing_label: scalar or string or np.nan or None, default=np.nan\n",
    "        Value to represent a missing label\n",
    "    random_state: int or np.random.RandomState\n",
    "        The random state to use\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    [1] O. Sener und S. Savarese, „ACTIVE LEARNING FOR CONVOLUTIONAL NEURAL \n",
    "    NETWORKS: A CORE-SET APPROACH“, 2018.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self, method='greedy', missing_label=MISSING_LABEL, random_state=None\n",
    "    ):\n",
    "        super().__init__(\n",
    "            missing_label=missing_label, random_state=random_state\n",
    "        )\n",
    "\n",
    "        self.method = method\n",
    "\n",
    "    def query(\n",
    "            self,\n",
    "            X,\n",
    "            y,\n",
    "            candidates=None,\n",
    "            batch_size=1,\n",
    "            return_utilities=False,\n",
    "            **kwargs\n",
    "    ):\n",
    "\n",
    "        \"\"\" Query the next instances to be labeled\n",
    "\n",
    "         Parameters\n",
    "         ----------\n",
    "         **kwargs\n",
    "         X: array-like of shape (n_samples, n_features)\n",
    "            Training data set, usually complete, i.e. including the labeled and\n",
    "            unlabeled samples\n",
    "         y: array-like of shape (n_samples, )\n",
    "            Labels of the training data set (possibly including unlabeles ones\n",
    "            indicated by self.missing_label)\n",
    "         candidates: None or array-like of shape (n_candidates), dtype = int or\n",
    "            array-like of shape (n_candidates, n_features),\n",
    "            optional (default=None)\n",
    "            If candidates is None, the unlabeled samples from (X,y) are considered\n",
    "            as candidates\n",
    "         batch_size: int, optional(default=1)\n",
    "            The number of samples to be selectes in one AL cycle.\n",
    "         return_utilities: bool, optional(default=False)\n",
    "            If True, also return the utilites based on the query strategy\n",
    "\n",
    "         Returns\n",
    "         ----------\n",
    "         query_indices: numpy.ndarry of shape (batch_size, )\n",
    "            The query_indices indicate for which candidate sample a label is\n",
    "            to queried, e.g., `query_indices[0]` indicates the first selected\n",
    "            sample.\n",
    "         utilities: numpy.ndarray of shape (n_samples, )\n",
    "            The distance between each data point and its nearest center after\n",
    "            each selected sample of the batch\n",
    "         \"\"\"\n",
    "\n",
    "        X, y, candidates, batch_size, return_utilities = self._validate_data(\n",
    "            X, y, candidates, batch_size, return_utilities, reset=True\n",
    "        )\n",
    "\n",
    "        X_cand, mapping = self._transform_candidates(candidates, X, y)\n",
    "        \"\"\"\n",
    "        X_cand unlabeled samples\n",
    "        mapping: indices of the original array\n",
    "        \"\"\"\n",
    "\n",
    "        if self.method == 'greedy':\n",
    "            if mapping is not None:\n",
    "                query_indices, utilities = k_greedy_center(X, y, batch_size, self.random_state_, self.missing_label, mapping)\n",
    "            else:\n",
    "                X_with_cand = np.concatenate((X, X_cand), axis=0)\n",
    "                n_new_cand = X_cand.shape[0]\n",
    "                y_cand = np.full(shape=n_new_cand, fill_value=self.missing_label)\n",
    "                y_with_cand = np.concatenate((y, y_cand), axis=None)\n",
    "                mapping = np.arange(X.shape[0], X.shape[0] + n_new_cand)\n",
    "                query_indices, utilities = k_greedy_center(X_with_cand, y_with_cand, batch_size,self.random_state_, self.missing_label, mapping, n_new_cand)\n",
    "\n",
    "        if return_utilities:\n",
    "            return query_indices, utilities\n",
    "        else:\n",
    "            return query_indices\n",
    "\n",
    "def k_greedy_center(X, y, batch_size, random_state, missing_label=MISSING_LABEL, mapping=None, n_new_cand=None):\n",
    "    \"\"\"\n",
    "     An active learning method that greedily forms a batch to minimize\n",
    "     the maximum distance to a cluster center among all unlabeled\n",
    "     datapoints.\n",
    "\n",
    "     Parameters:\n",
    "     ----------\n",
    "     X: array-like of shape (n_samples, n_features)\n",
    "        Training data set, usually complete, i.e. including the labeled and\n",
    "        unlabeled samples\n",
    "     selected_samples: np.ndarray of shape (n_selected_samples, )\n",
    "        index of datapoints already selectes\n",
    "     batch_size: int, optional(default=1)\n",
    "        The number of samples to be selected in one AL cycle.\n",
    "        \n",
    "     Return:\n",
    "     ----------\n",
    "     new_samples: numpy.ndarry of shape (batch_size, )\n",
    "         The query_indices indicate for which candidate sample a label is\n",
    "         to queried from the candidates\n",
    "     utilities: numpy.ndarray of shape (batch_size, n_samples)\n",
    "         The distance between each data point and its nearest center that used\n",
    "         for selecting the next sample.\n",
    "        \"\"\"\n",
    "    # read the labeled aka selected samples from the y vector\n",
    "    selected_samples = labeled_indices(y, missing_label=missing_label)\n",
    "    if mapping is None:\n",
    "        mapping = unlabeled_indices(y, missing_label=missing_label)\n",
    "    # initialize the utilities matrix with\n",
    "    utilities = np.empty(shape=(batch_size, X.shape[0]))\n",
    "\n",
    "    query_indices = np.array([], dtype=int)\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        utilities[i] = update_distances(X, selected_samples, mapping)\n",
    "\n",
    "        # select index\n",
    "        idx = np.nanargmax(utilities[i])\n",
    "\n",
    "        if len(selected_samples) == 0:\n",
    "            idx = random_state.choice(mapping)\n",
    "            # because np.nanargmax always return the first occurrence is returned\n",
    "\n",
    "        query_indices = np.append(query_indices, [idx])\n",
    "        selected_samples = np.append(selected_samples, [idx])\n",
    "\n",
    "    if n_new_cand is not None:\n",
    "        utilities = utilities[:, mapping]\n",
    "\n",
    "    return query_indices, utilities\n",
    "\n",
    "def update_distances(X, cluster_centers, mapping):\n",
    "    \"\"\"\n",
    "    Update min distances by given cluster centers.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    X: array-like of shape (n_samples, n_features)\n",
    "        Training data set, usually complete, i.e. including the labeled and\n",
    "        unlabeled samples\n",
    "    cluster_centers: indices of cluster centers\n",
    "\n",
    "    Return:\n",
    "    ---------\n",
    "    dist: numpy.ndarray of shape (1, n_samples)\n",
    "        - if there aren't any cluster centers existed, the default distance\n",
    "            will be 0\n",
    "        - if there are some cluster center existed, the return will be the\n",
    "            distance between each data point and its nearest center after\n",
    "            each selected sample of the batch\n",
    "        \"\"\"\n",
    "    dist = np.empty(shape=(1, X.shape[0]))\n",
    "\n",
    "    if len(cluster_centers) > 0:\n",
    "        cluster_center_feature = X[cluster_centers]\n",
    "        dist_matrix = pairwise_distances(X, cluster_center_feature)\n",
    "        dist = np.min(dist_matrix, axis=1).reshape(1, -1)\n",
    "\n",
    "    result_dist = np.full((1, X.shape[0]), np.nan)\n",
    "    result_dist[0, mapping] = dist[0, mapping]\n",
    "    result_dist[0, cluster_centers] = np.nan\n",
    "\n",
    "    return result_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = np.random.RandomState(0)\n",
    "X, y_true = make_blobs(n_samples=10, n_features=2,\n",
    "                       centers=[[0, 1], [-3, .5], [-1, -1], [2, 1], [1, -.5]],\n",
    "                       cluster_std=.7, random_state=random_state)\n",
    "y_true = y_true % 2\n",
    "y = np.full(shape=y_true.shape, fill_value=MISSING_LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "qs = CoreSet(method='greedy', random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cand, _ = make_blobs(n_samples=5, n_features=2,\n",
    "                       centers=[[0, 1], [-3, .5], [-1, -1], [2, 1], [1, -.5]],\n",
    "                       cluster_std=.7, random_state=np.random.RandomState(1))\n",
    "X_with_cand = np.concatenate((X, X_cand), axis=0)\n",
    "n_new_cand = X_cand.shape[0]\n",
    "y_cand = np.full(shape=n_new_cand, fill_value=np.nan)\n",
    "y_with_cand = np.concatenate((y, y_cand), axis=None)\n",
    "mapping = np.arange(X.shape[0], X.shape[0] + n_new_cand)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.66323560e-317 1.07284626e-317 0.00000000e+000 0.00000000e+000\n",
      "  0.00000000e+000]\n",
      " [2.08695023e+000 1.24931306e+000 4.58126438e+000             nan\n",
      "  3.53203412e+000]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "query_idx, utilities = qs.query(X=X, y=y, batch_size=2, return_utilities=True, candidates=X_cand)\n",
    "print(utilities)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
